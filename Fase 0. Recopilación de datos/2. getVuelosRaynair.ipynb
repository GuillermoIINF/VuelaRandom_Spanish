{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 0: <i>Recopilación de datos</i>\n",
    "## <b>Obtención de los vuelos y precios de <i>ryanair.com</i></b>\n",
    "\n",
    "&emsp;&emsp;Con este archivo se procede a recopilar la información de los vuelos y precios de la página <b>ryanair.com</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.IMPORTACIÓN DE LIBRERIAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from time import sleep, strftime\n",
    "import random\n",
    "from random import randint\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from time import sleep, strftime\n",
    "from datetime import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.CARGA DE LOS DATOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cargan los datos para obtener las rutas (origenes y destinos) que existen actualmente en la compañía aérea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/ryanair.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. FILTRADO DE ORIGENES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtramos los origenes con los que va a trabajar la aplicación en su primera versión (Madrid, Barcelona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Source Airport']=='MAD')|(df['Source Airport']=='BCN')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. LISTA DESTINOS Y ORIGENES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean listas de origenes y destinos que iterarán en el proceso de Web Scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinos = list(df['Destination Airport'].values)\n",
    "origen = list(df['Source Airport'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. WEB SCRAPING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presenta el código de web Scraping para la web Ryanair.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Driver de chrome \n",
    "chrome_driver = \"chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para extraer vuelos\n",
    "def GetVuelos(soup, url, origen, destino, fecha_ida):\n",
    "    dfAux = pd.DataFrame(columns=['CAPTURA', 'FUENTE', 'ORIGEN', 'DESTINO', 'SALIDA', 'LLEGADA', 'PRECIO', \"URL\", \"AEROLINEA\"])\n",
    "    listaVuelos = soup.find_all(\"div\", class_='card-wrapper')\n",
    "    for i in range(len(listaVuelos)):\n",
    "        vuelo = listaVuelos[i]\n",
    "        hora = vuelo.find('div', {'data-ref':'flight-segment.departure'}).find('span', class_='h2').text.strip()\n",
    "        hora_llegada = vuelo.find('div', {'data-ref':'flight-segment.arrival'}).find('span', class_='h2').text.strip()\n",
    "        salida = fecha_ida +' '+ hora\n",
    "        llegada = fecha_ida +' '+ hora_llegada\n",
    "        try:\n",
    "            precio = float(vuelo.find('span', class_='price-value h2 text-700').text.replace('€','').replace(',','.').strip())\n",
    "        except:\n",
    "            precio = float(vuelo.find('span', class_='price-value h2 text-700 price-value--discounted').text.replace('€','').replace(',','.').strip())\n",
    "        dfAux = dfAux.append({\"CAPTURA\": datetime.now().strftime('%Y-%m-%d'), \"FUENTE\": \"Ryanair\", \"ORIGEN\":origen, \"DESTINO\":destino, \"SALIDA\":salida, \"LLEGADA\":llegada,\"PRECIO\":precio, \"URL\":url, \"AEROLINEA\":\"Ryanair\"}, ignore_index = True)\n",
    "    return dfAux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16h 42min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_vuelos = pd.DataFrame(columns=['CAPTURA', 'FUENTE', 'ORIGEN', 'DESTINO', 'SALIDA_IDA', 'LLEGADA_IDA', 'SALIDA_VUELTA', 'LLEGADA_VUELTA','PRECIO', \"URL\", \"AEROLINEA\"])\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--incognito\")\n",
    "navegador = webdriver.Chrome(executable_path=chrome_driver,options=chrome_options)\n",
    "\n",
    "fecha_ida = datetime(2020,10,1)\n",
    "fecha_vuelta = fecha_ida + timedelta(days=7)\n",
    "incrementoDia = timedelta(days=1)\n",
    "texto_fecha_ida = fecha_ida.strftime('%Y-%m-%d')\n",
    "texto_fecha_vuelta = fecha_vuelta.strftime('%Y-%m-%d')\n",
    "\n",
    "for k in range(90):\n",
    "    for j, i in zip(origen,destinos):\n",
    "        df_ida = pd.DataFrame(columns=['CAPTURA', 'FUENTE', 'ORIGEN', 'DESTINO', 'SALIDA', 'LLEGADA', 'PRECIO', \"URL\", \"AEROLINEA\"])\n",
    "        df_vuelta = pd.DataFrame(columns=['CAPTURA', 'FUENTE', 'ORIGEN', 'DESTINO', 'SALIDA', 'LLEGADA', 'PRECIO', \"URL\", \"AEROLINEA\"])\n",
    "        try:\n",
    "            url = 'https://www.ryanair.com/es/es/trip/flights/select?adults=1&teens=0&children=0&infants=0&dateOut='+texto_fecha_ida+'&dateIn='+texto_fecha_vuelta+'&originIata='+j+'&destinationIata='+i+'&isConnectedFlight=true&isReturn=true&discount=0&promoCode=&tpAdults=1&tpTeens=0&tpChildren=0&tpInfants=0&tpStartDate='+texto_fecha_ida+'&tpEndDate='+texto_fecha_vuelta+'&tpOriginIata='+j+'&tpDestinationIata='+i+'&tpIsConnectedFlight=true&tpIsReturn=true&tpDiscount=0&tpPromoCode='\n",
    "            navegador.implicitly_wait(20)\n",
    "            navegador.get(url) \n",
    "            sleep(randint(3,6))\n",
    "            source = navegador.page_source\n",
    "            soup = BeautifulSoup(source)\n",
    "            soup2 = soup.find(\"button\", {'data-ref':texto_fecha_ida})\n",
    "            soup3 = soup.find(\"button\", {'data-ref':texto_fecha_vuelta})\n",
    "            try:\n",
    "                precio1 = soup2.find(\"span\", class_=\"price__integers carousel-date-price--selected\").text.strip()\n",
    "                precio2 = soup3.find(\"span\", class_=\"price__integers carousel-date-price--selected\").text.strip()\n",
    "                if int(precio1) >0 and int(precio2) >0:\n",
    "                    soup_ida = soup.find(\"div\", class_=\"ng-tns-c31-8 ng-star-inserted\")\n",
    "                    soup_vuelta = soup.find(\"div\", class_=\"ng-tns-c31-11 ng-star-inserted\")\n",
    "                    datos = GetVuelos(soup_ida,url,j,i,texto_fecha_ida)\n",
    "                    df_ida = df_ida.append(datos)\n",
    "                    datos = GetVuelos(soup_vuelta,url,j,i,texto_fecha_vuelta)\n",
    "                    df_vuelta = df_vuelta.append(datos)\n",
    "            except:\n",
    "                continue\n",
    "        except:\n",
    "            print('No existe vuelo')\n",
    "            continue\n",
    "        finally:\n",
    "            for fila_ida in range(len(df_ida)):\n",
    "                for fila_vuelta in range(len(df_vuelta)):\n",
    "                    df_vuelos = df_vuelos.append({'CAPTURA': df_ida['CAPTURA'].iat[fila_ida], \n",
    "                                                  \"FUENTE\": \"Ryanair\", \n",
    "                                                  \"ORIGEN\":j, \n",
    "                                                  \"DESTINO\":i, \n",
    "                                                  \"SALIDA_IDA\":df_ida[\"SALIDA\"].iat[fila_ida], \n",
    "                                                  \"LLEGADA_IDA\":df_ida[\"LLEGADA\"].iat[fila_ida], \n",
    "                                                  \"SALIDA_VUELTA\":df_vuelta[\"SALIDA\"].iat[fila_vuelta], \n",
    "                                                  \"LLEGADA_VUELTA\":df_vuelta[\"LLEGADA\"].iat[fila_vuelta],\n",
    "                                                  \"PRECIO\":df_ida[\"PRECIO\"].iat[fila_ida]+df_vuelta[\"PRECIO\"].iat[fila_vuelta],\n",
    "                                                  \"URL\": df_ida[\"URL\"].iat[fila_ida],\n",
    "                                                  \"AEROLINEA\":'Ryanair'}, \n",
    "                                                  ignore_index = True) \n",
    "            sleep(randint(3,6))\n",
    "            \n",
    "    fecha_ida += incrementoDia\n",
    "    fecha_vuelta += incrementoDia\n",
    "    texto_fecha_ida = fecha_ida.strftime('%Y-%m-%d')\n",
    "    texto_fecha_vuelta = fecha_vuelta.strftime('%Y-%m-%d')\n",
    "navegador.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GUARDADO DE LOS DATOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar, se guarda el archivo como data_ryanair.csv o se sobreescribe si ya existe. Ruta relativa \"../../data/data_ryanair.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "if path.exists('../../data/data_ryanair.csv'):\n",
    "    df_vuelos.to_csv('../../data/data_ryanair.csv', mode='a', header=False)\n",
    "else:\n",
    "    df_vuelos.to_csv(\"../../data/data_ryanair.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
